{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A08 Q2: RNN and BPTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from termcolor import colored  # for printing coloured text\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "class Origin(torch.utils.data.Dataset):\n",
    "    '''\n",
    "     ds = Origin(seq_length=10, start=0, stop=-1)\n",
    "     \n",
    "     Creates a PyTorch Dataset object, holding a simplified version\n",
    "     of the text from Charles Darwin's \"On the Origin of Species\".\n",
    "     \n",
    "     The class contains utility functions to convert between the\n",
    "     string-based form of a sequence, and its vector encoding, in which\n",
    "     each character is represented by a one-hot 28-vector corresponding\n",
    "     to the 28 characters in the string\n",
    "       ' .abcdefghijklmnopqrstuvwxyz'  (the first character is a space)\n",
    "     \n",
    "     The target sequences are the same as the inputs, but advanced by\n",
    "     one character.\n",
    "     \n",
    "     Inputs:\n",
    "      seq_length  the number of characters in each sequence\n",
    "      start       the index of the character to start taking sequences from\n",
    "      stop        the index of the character to stop taking sequences from\n",
    "      \n",
    "     Usage:\n",
    "      ds = Origin(seq_length=5, start=7, stop=100)\n",
    "      x,t = ds.__getitem__(0)\n",
    "      print(ds.read_seq(x))   # Produces 'origi'\n",
    "      print(ds.read_seq(t))   # Produces 'rigin'\n",
    "    '''\n",
    "    def __init__(self, seq_length=10, start=0, stop=-1):\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "        orig_text = open('origin_of_species.txt').read().lower()\n",
    "        chars = sorted(list(set(orig_text)))\n",
    "        chars.insert(0, \"\\0\") #Add newline character\n",
    "        vocab_size = len(chars)\n",
    "\n",
    "        char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "        indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "        idx = [char_indices[c] for c in orig_text]\n",
    "\n",
    "        # Let's simplify it by keeping only letters, spaces, and periods.\n",
    "        filt_idx = []\n",
    "        for i in idx:\n",
    "            if i<=24 and i!=10:\n",
    "                filt_idx.append(2)\n",
    "            elif i>24 or i==10:\n",
    "                filt_idx.append(i)\n",
    "        blah = ''.join([indices_char[f] for f in filt_idx])\n",
    "        self.text = re.sub(' +', ' ', blah)  # collapse multiple spaces using regular expressions\n",
    "        self.text = self.text[start:stop]\n",
    "        #chars = sorted(list(set(self.text)))\n",
    "        chars = sorted(list(set(' .abcdefghijklmnopqrstuvwxyz')))\n",
    "        self.vocab_size = len(chars)\n",
    "        print('Character set: '+''.join(chars)+' (first char is a space)')\n",
    "\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "        self.idx = [self.char_indices[c] for c in self.text]\n",
    "\n",
    "        print('There are '+str(self.vocab_size)+' characters in our character set')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text) - 1 - self.seq_length\n",
    "    \n",
    "    def __getitem__(self, k):\n",
    "        x = self.idx[k:k+self.seq_length]\n",
    "        t = self.idx[k+1:k+1+self.seq_length]\n",
    "        return self.seq_i2v(x), torch.tensor(t, dtype=torch.long)\n",
    "      \n",
    "    def seq_i2v(self, seq):\n",
    "        x = torch.zeros((len(seq), self.vocab_size))\n",
    "        for k,i in enumerate(seq):\n",
    "            x[k,i] = 1.\n",
    "        return x\n",
    "    \n",
    "    def read_seq(self, x):\n",
    "        idx = [torch.argmax(v).item() for v in x]        \n",
    "        return ''.join(self.indices_char[i] for i in idx)\n",
    "    \n",
    "    def encode_seq(self, c):\n",
    "        idx = [self.char_indices[cc] for cc in c]\n",
    "        return self.seq_i2v(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "oos = Origin(start=11000, stop=21000, seq_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many sequences?\n",
    "len(oos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You can access the original (simplified) text.\n",
    "oos.text[820:900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = oos.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Here is how you can view one of the samples:')\n",
    "print(f'Sample input: \"{oos.read_seq(x)}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyTorch DataLoader\n",
    "dl = torch.utils.data.DataLoader(oos, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `GRU` Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    '''\n",
    "     net = GRU(dims)\n",
    "     Input:\n",
    "       dims is [I, H], where the input/output layers have I neurons, and the\n",
    "            hidden layer has H neurons.\n",
    "    '''\n",
    "    def __init__(self, dims):\n",
    "        super().__init__()\n",
    "        self.losses = []\n",
    "        \n",
    "        #===== YOUR CODE HERE =====\n",
    "        self.input_dim, self.hidden_dim = dims\n",
    "        self.replace_me = nn.Linear(self.input_dim, self.input_dim)\n",
    "\n",
    "        \n",
    "        \n",
    "    def step(self, x, h):\n",
    "        '''\n",
    "         hnext = net.step(x, h)\n",
    "         \n",
    "         Takes a time step, with input x and current hidden state h.\n",
    "         Returns the new h.\n",
    "         \n",
    "         Inputs:\n",
    "          x      a DxI tensor holding a batch of inputs, where\n",
    "                    D is the batch size, and\n",
    "                    I is the dimension of the inputs\n",
    "          h      a DxH tensor holding a batch of hidden states, where\n",
    "                    H is the number of hidden nodes\n",
    "                \n",
    "         Output:\n",
    "          hnext  a DxH tensor holding the hidden states for the next\n",
    "                    timestep\n",
    "        '''\n",
    "        #===== YOUR CODE HERE =====\n",
    "        return h  # <-- Replace this line\n",
    "    \n",
    "    \n",
    "    def output(self, h):\n",
    "        '''\n",
    "         y = net.output(h)\n",
    "         \n",
    "         Given the hidden state, returns the *log* of the output.\n",
    "         ie. for categorical cross-entropy, it should return LogSoftmax.\n",
    "         \n",
    "         Input:\n",
    "          h  a DxH tensor holding a batch of hidden states, where\n",
    "                D is the batch size, and\n",
    "                H is the dimension of the hidden state (number of hidden nodes)\n",
    "                \n",
    "         Output:\n",
    "          y  a DxI tensor holding a batch of outputs, where\n",
    "                I is the dimension of the output\n",
    "        '''\n",
    "        #===== YOUR CODE HERE =====\n",
    "        return torch.zeros((len(h), self.input_dim))  # <-- Replace this line\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "         y = net.forward(x)\n",
    "         \n",
    "         Takes a batch of squences, and returns the batch of output\n",
    "         sequences.\n",
    "         \n",
    "         Inputs:\n",
    "          x   a DxTxI tensor, where\n",
    "                 D is the batch size (number of sequences in the batch)\n",
    "                 T is the sequence length, and\n",
    "                 I is the dimension of the input to the network\n",
    "                 \n",
    "         Output:\n",
    "          y   a DxTxI tensor, as above\n",
    "        '''\n",
    "        x = x.to(device)  # in case you're using a GPU\n",
    "        # We have to reorder the batch from (D, T, I) to (T, D, I) so that\n",
    "        # we can run the batch through the network, one timestep at a time.\n",
    "        seq_of_batches = torch.einsum('ijk->jik', x)\n",
    "\n",
    "        output_seq = []\n",
    "        T, samples, input_dim = seq_of_batches.shape\n",
    "        h = torch.zeros((samples, self.hidden_dim)).to(device)\n",
    "        for xt in seq_of_batches:\n",
    "            h = self.step(xt, h)\n",
    "            output_seq.append(self.output(h))\n",
    "        y = torch.stack(output_seq, dim=0).to(device)  # (T, batch_size, output_dim)\n",
    "        return torch.einsum('jik->ijk', y)  # (batch_size, T, output_dim)\n",
    "\n",
    "    \n",
    "    def bptt(self, dl, epochs=10, loss_fcn=nn.NLLLoss(), lr=0.001):\n",
    "        '''\n",
    "         net.bptt(dl, epochs=10, loss_fcn=nn.NLLLoss(), lr=0.001)\n",
    "         \n",
    "         Trains the recurrent network using Backprop Through Time.\n",
    "         \n",
    "         Inputs:\n",
    "          dl        PyTorch DataLoader object\n",
    "                    Each batch shoud be shaped DxTxI where\n",
    "                      D is the number of sequences (samples) in the batch,\n",
    "                      T is the length of each sequence, and\n",
    "                      I is dim of each input to the network\n",
    "          epochs    number of epochs to train for\n",
    "          loss_fcn  PyTorch loss function\n",
    "          lr        learning rate\n",
    "        '''\n",
    "        optim = torch.optim.Adam(self.parameters(), lr=lr)  # optimizer\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            total_loss = 0.\n",
    "            for x,t in (dl):\n",
    "                y = self(x)   # process the batch of sequences\n",
    "                \n",
    "                # Go through output sequences, and compute loss\n",
    "                loss = torch.tensor(0., device=device, requires_grad=True)\n",
    "                for ys,ts in zip(y,t.to(device)):\n",
    "                    loss = loss + loss_fcn(ys, ts)\n",
    "                    \n",
    "                # And this stuff is familiar by now\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                total_loss += loss.detach().cpu().item()\n",
    "                \n",
    "            self.losses.append(total_loss/len(dl))\n",
    "        plt.plot(self.losses)\n",
    "        \n",
    "        \n",
    "    def predict(self, x, n=10):\n",
    "        '''\n",
    "         y = net.predict(x, n=10)\n",
    "         \n",
    "         Run the network on sequence x, and then continue to predict\n",
    "         the next n outputs.\n",
    "         \n",
    "         Inputs:\n",
    "          x  a TxI tensor for a single input sequence\n",
    "          n  how many output timesteps to predict\n",
    "          \n",
    "         Output:\n",
    "          y  an (n)xI tensor, holding the sequence of n outputs\n",
    "                predicted after the input sequence\n",
    "        '''\n",
    "        assert len(x.shape)==2\n",
    "        with torch.no_grad():\n",
    "            h = torch.zeros((1, self.hidden_dim)).to(device)\n",
    "            for xx in x:  # step through the given sequence\n",
    "                h = self.step(xx, h)\n",
    "            y = self.output(h)\n",
    "            pred = [y]   # for storing the output sequence\n",
    "            \n",
    "            # Now we take n more steps, and add the network's output\n",
    "            for t in range(n-1):\n",
    "                # Make a one-hot input out of the last output\n",
    "                c = torch.argmax(y)\n",
    "                x = torch.zeros_like(y)\n",
    "                x[0,c] = 1.\n",
    "                # Take a timestep\n",
    "                h = self.step(x, h)\n",
    "                y = self.output(h) # output from prev step becomes input to next step\n",
    "                pred.append(y)\n",
    "                \n",
    "        return torch.stack(pred, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and train the GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GRU([oos.vocab_size, 400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net.bptt(dl, epochs=20, loss_fcn=nn.NLLLoss(reduction='mean'), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these lines to save and load your trained network.\n",
    "#torch.save(net.cpu(), 'mygru.pt')\n",
    "#net = torch.load('mygru.pt').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a random seed sequence\n",
    "k = np.random.randint(0, high=len(oos))\n",
    "rs = oos.read_seq  # shorthand for the function\n",
    "s = oos.__getitem__(k)[0].to(device)  # s holds the seq\n",
    "\n",
    "# Feed the seq in to the net, and ask for the next 10 characters\n",
    "pred_seq = net.predict(s, n=10).cpu()\n",
    "\n",
    "print(f'Input:        {rs(s)}')\n",
    "print(f'Prediction:   {rs(s)+colored(rs(pred_seq), \"red\")}')\n",
    "snext = oos.__getitem__(k+oos.seq_length)[0]  # the following sequence\n",
    "print(f'Actual:       {rs(s)+rs(snext)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's predict a longer sequence\n",
    "word = 'ch species'  # choosing our own see seq\n",
    "v = oos.encode_seq(word)  # encode it\n",
    "y = net.predict(v, n=50)  # predict next 50 characters\n",
    "print(f'{oos.read_seq(v)}'+colored(oos.read_seq(y), 'red'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching string length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiment on a bunch of random seed sequences.\n",
    "# - choose random seed seq\n",
    "# - predict next 100 characters\n",
    "# - find out how many characters match the text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot matching-length vs trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
